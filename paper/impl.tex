\section{Implementation}

The NVKV library was implemented with about 600 lines of dense C code, including
a 50 line header file to be used by applications. It does not implement much of
the functionality of \bdb because that is out of scope. Much of the complexity
of the code has to do with translating pointers. For example, the hash table
stores not the keys themselves (since they can be arbitrary length), but
pointers to the keys in the data address space. To translate such a pointer to
the appropriate virtual address that the database is mapped to, it is passed
through the function \texttt{ptr\_translate}, which adjusts it according to
figure~\ref{fig:addrspace} and adds to it the base address of the database
mapping. The result can be dereferenced normally, and points directly to the
persistent data. Another added complexity is that because the virtual address
space is an interleaving of the metadata and data spaces, the $n$th bucket
cannot be loaded simply by adding $n$ to the base pointer for the table.
Instead, bucket lookups must also go through the \texttt{ptr\_translate}
function, adding to the complexity of implementing the hash table manipulation
functions.

\subsection{Consistency Mechanisms}

The code implements two consistency mechanisms: \texttt{persist-release} and
transactions. Both are emulated in leu of having true BNVM. The
\texttt{persist-release} operation is implemented as a store fence, a cache-line
write-back (\texttt{clwb} on Intel), followed by a full fence. The result is
that the cache-line is persisted while reordering is restricted. Transactions
are emulated, under the assumption that each memory access takes some number of
additional cycles when the transaction commits.


\subsection{Generated Transaction Code}

As discussed previously, one of the design goals was to reduce the size of
transactions as much as possible. The implementation of \texttt{put} was
designed with this in mind, and is split into two parts: data recording and
indexing. In the data recording phase, the data contained in the key and value
\texttt{DBT}s are saved into BNVM.
The data recording
phase does not require transactions since each write maintains correctness; thus
the data recording phase uses only \texttt{persist-release} operations. The
indexing phase, however, uses transactions when updating the hash table.

The design of the cuckoo hash table combined with the choice to not move data
when rehashing means that the hash table uses only two transaction blocks for
\texttt{put}:
\begin{enumerate}
\item \texttt{do\_move}: Copy one bucket to another and zero the source bucket.
\item \texttt{do\_insert}: Write a new key and value pointer into a bucket.
\end{enumerate}
%TODO: make sure we motivate this earlier
Each of these transaction blocks is implemented as a separate function so I
could experiment with the results of using \texttt{-Os} to optimize the blocks
for size rather than speed, an important potential optimization for
transactions that are limited in size or do not scale well with the number of
memory references.

Listings~\ref{lst:moveO3} and~\ref{lst:insertO3} show the generated code for
\texttt{do\_move} and \texttt{do\_insert} respectively when using gcc 7.3.0 on
an Intel x86\_64 processor with native code generation. The result is very
compact, with only the required instructions inside the transaction blocks.
Importantly, for move, the number of memory references is the minimum required to
accomplish the goal of the transaction. However, for insert, the generated code
contains a false dependency: the first line (\texttt{mov -0x68(\%rbp),\%rdi})
does a memory read that does not \textit{need} to be in the transaction block,
it could have been done before the transaction begins.
Compiler or language support would be required to fully optimize transactions
like this.


\begin{lstlisting}[caption={Transaction code generations for do\_move, optimized for speed.
Five instructions, five memory accesses (four writes).},label={lst:moveO3}]
     vmovdqu (%rbx), %xmm0
     mov     %r9, 0x10(%r12)
     vmovups %xmm0, (%r12)
     movq    $0x0, 0x10(%rbx)
     movq    $0x0, (%rbx)
\end{lstlisting}

\begin{lstlisting}[caption={Transaction code generation for do\_insert, optimized for speed.
Four instructions, four memory accesses (three writes).},label=lst:insertO3]
    mov    -0x68(%rbp),%rdi
    mov    %r13,(%rax)
    movq   $0x1,0x10(%rax)
    mov    %rdi,0x8(%rax)
\end{lstlisting}
%$


After applying size optimizations, as shown in Listings~\ref{lst:moveOs}
and~\ref{lst:insertOs}, the insert block is smaller with fewer memory
references. In fact, it no longer contains the false dependency, and contains
the minimum number of memory accesses, but it does have
an extra instruction (\texttt{movslq}) which again does not \textit{need} to be in the block, thus
further motivating language support. The move operation, however, has
\textit{increased} in size dramatically, containing two instructions which need
not be in the transaction block. However, some of the additional instructions
and memory references come from the fact that gcc chose not to use vector
operations to do the copy in this case, relying instead on simple \texttt{mov}s.
Why this is the case is unknown, although we speculate that the reason gcc
chose to do these optimizations was to reduce the number of times these code
blocks appeared in the generated assembly. Whereas the speed-optimized versions
appeared in numerous places throughout the code, the size-optimzed ones were
condensed into one location to reduce size, and therefore gcc was unable to
prove that the \texttt{xmm} registers were available for use. While the result
appears to have more memory references, the two blocks, size and speed optimzed,
touch exactly the same amount of memory\footnote{The \texttt{xmm} registers
access larger amounts of memory because they are vector registers.}
(as expected, since they do the same thing).
The important point is that optimizing for size on gcc does not necessarily
optimize for the size of individual blocks of code because the compiler tries to
reduce the size of the program as a whole.




\begin{lstlisting}[caption={Transaction code generation for do\_move, optimized for size.
Eight instructions, seven memory accesses (five writes).},label=lst:moveOs]
     mov    (%rsi),%rax
     movslq %edx,%rdx
     mov    %rax,(%rdi)
     mov    0x8(%rsi),%rax
     mov    %rdx,0x10(%rdi)
     mov    %rax,0x8(%rdi)
     movq   $0x0,0x10(%rsi)
     movq   $0x0,(%rsi)
\end{lstlisting}

\begin{lstlisting}[caption={Transaction code generation for do\_insert, optimized for size.
Four instructions, three memory accesses (three writes).},label=lst:insertOs]
     movslq %r8d,%r8
     mov    %rdx,(%rsi)
     mov    %rcx,0x8(%rsi)
     mov    %r8,0x10(%rsi)
\end{lstlisting}



